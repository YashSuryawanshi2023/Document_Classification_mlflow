{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99e62628-2e01-4d44-ba79-8514b81a36b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /home/hduser/.local/lib/python3.10/site-packages (2.4.1)\n",
      "Requirement already satisfied: filelock in /home/hduser/.local/lib/python3.10/site-packages (from torch) (3.13.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/hduser/.local/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/hduser/.local/lib/python3.10/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: networkx in /home/hduser/.local/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/hduser/.local/lib/python3.10/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/hduser/.local/lib/python3.10/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/hduser/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/hduser/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/hduser/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/hduser/.local/lib/python3.10/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/hduser/.local/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/hduser/.local/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/hduser/.local/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/hduser/.local/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/hduser/.local/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/hduser/.local/lib/python3.10/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/hduser/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/hduser/.local/lib/python3.10/site-packages (from torch) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/hduser/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.77)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/hduser/.local/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/hduser/.local/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6216d139-b46b-48f2-9463-96343ceb5b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# teams specific credentials\n",
    "os.environ['MLFLOW_TRACKING_USERNAME'] = 'YashSuryawanshi2023' \n",
    "os.environ['MLFLOW_TRACKING_PASSWORD'] = 'b4eee9da1a851a3650b180edd9469ee7a716f403' \n",
    "os.environ['MLFLOW_TRACKING_URI'] = 'https://dagshub.com/YashSuryawanshi2023/mlflowdemoproject.mlflow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ae9d48d-30f9-40e0-b13d-1b47bd7e0c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy==1.21.5 in /home/hduser/.local/lib/python3.10/site-packages (1.21.5)\n",
      "Requirement already satisfied: scikit-learn==1.1.3 in /home/hduser/.local/lib/python3.10/site-packages (1.1.3)\n",
      "Requirement already satisfied: threadpoolctl==3.1.0 in /home/hduser/.local/lib/python3.10/site-packages (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/hduser/.local/lib/python3.10/site-packages (from scikit-learn==1.1.3) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /home/hduser/.local/lib/python3.10/site-packages (from scikit-learn==1.1.3) (1.4.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy==1.21.5 scikit-learn==1.1.3 threadpoolctl==3.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69d01cae-5cfa-40f7-ba26-9764ebd4f630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pdf2image in /usr/local/lib/python3.10/dist-packages (1.17.0)\n",
      "Requirement already satisfied: pillow in /home/hduser/.local/lib/python3.10/site-packages (from pdf2image) (10.4.0)\n",
      "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pytesseract in /home/hduser/.local/lib/python3.10/site-packages (0.3.13)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/hduser/.local/lib/python3.10/site-packages (from pytesseract) (23.2)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in /home/hduser/.local/lib/python3.10/site-packages (from pytesseract) (10.4.0)\n",
      "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pdf2image in /usr/local/lib/python3.10/dist-packages (1.17.0)\n",
      "Requirement already satisfied: pillow in /home/hduser/.local/lib/python3.10/site-packages (from pdf2image) (10.4.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pdfminer.six in /home/hduser/.local/lib/python3.10/site-packages (20240706)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in /home/hduser/.local/lib/python3.10/site-packages (from pdfminer.six) (3.3.2)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /home/hduser/.local/lib/python3.10/site-packages (from pdfminer.six) (41.0.7)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/hduser/.local/lib/python3.10/site-packages (from cryptography>=36.0.0->pdfminer.six) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /home/hduser/.local/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.21)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: datasets in /home/hduser/.local/lib/python3.10/site-packages (3.0.1)\n",
      "Requirement already satisfied: filelock in /home/hduser/.local/lib/python3.10/site-packages (from datasets) (3.13.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/hduser/.local/lib/python3.10/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/hduser/.local/lib/python3.10/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/hduser/.local/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/hduser/.local/lib/python3.10/site-packages (from datasets) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/hduser/.local/lib/python3.10/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/hduser/.local/lib/python3.10/site-packages (from datasets) (4.66.5)\n",
      "Requirement already satisfied: xxhash in /home/hduser/.local/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /home/hduser/.local/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /home/hduser/.local/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /home/hduser/.local/lib/python3.10/site-packages (from datasets) (3.10.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.22.0 in /home/hduser/.local/lib/python3.10/site-packages (from datasets) (0.25.1)\n",
      "Requirement already satisfied: packaging in /home/hduser/.local/lib/python3.10/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/hduser/.local/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/hduser/.local/lib/python3.10/site-packages (from aiohttp->datasets) (2.3.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/hduser/.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/hduser/.local/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/hduser/.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/hduser/.local/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/hduser/.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/hduser/.local/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/hduser/.local/lib/python3.10/site-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/hduser/.local/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.32.2->datasets) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.32.2->datasets) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/hduser/.local/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/hduser/.local/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->datasets) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/hduser/.local/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/hduser/.local/lib/python3.10/site-packages (4.45.1)\n",
      "Requirement already satisfied: filelock in /home/hduser/.local/lib/python3.10/site-packages (from transformers) (3.13.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/hduser/.local/lib/python3.10/site-packages (from transformers) (0.25.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/hduser/.local/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/hduser/.local/lib/python3.10/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/hduser/.local/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/hduser/.local/lib/python3.10/site-packages (from transformers) (2024.7.24)\n",
      "Requirement already satisfied: requests in /home/hduser/.local/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/hduser/.local/lib/python3.10/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/hduser/.local/lib/python3.10/site-packages (from transformers) (0.20.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/hduser/.local/lib/python3.10/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/hduser/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/hduser/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/hduser/.local/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->transformers) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/hduser/.local/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pdf2image\n",
    "!apt-get install poppler-utils\n",
    "!pip install pytesseract\n",
    "!apt-get install tesseract-ocr\n",
    "!pip install pdf2image\n",
    "!pip install pdfminer.six\n",
    "!pip install datasets\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c2c19a4-a0c9-4be7-acdf-2501b32f1b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fb93a43-959f-40d3-ad80-b6bc682aa9d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_type</th>\n",
       "      <th>text</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>po_first_page</td>\n",
       "      <td>vendor code10221985 rotex manufacturers  engin...</td>\n",
       "      <td>/home/parthpatil/Documents/testing_data/Data_2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>po_next_page</td>\n",
       "      <td>10221985 otnheft rotex manufacturers  engineer...</td>\n",
       "      <td>/home/parthpatil/Documents/testing_data/Data_2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>po_first_page</td>\n",
       "      <td>vendor code10221985 rotex manufacturers  engin...</td>\n",
       "      <td>/home/parthpatil/Documents/testing_data/Data_2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>po_next_page</td>\n",
       "      <td>10221985 rotex manufacturers  engineers privat...</td>\n",
       "      <td>/home/parthpatil/Documents/testing_data/Data_2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>po_first_page</td>\n",
       "      <td>vendor code10221985 rotex manufacturers  engin...</td>\n",
       "      <td>/home/parthpatil/Documents/testing_data/Data_2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>gstn_first_page</td>\n",
       "      <td>amended government of india form gst reg06 see...</td>\n",
       "      <td>/home/parthpatil/Documents/testing_data/Data_3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>pnl_first_page</td>\n",
       "      <td>kyocera document solutions india private limit...</td>\n",
       "      <td>/home/parthpatil/Documents/testing_data/Data_3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>pnl_first_page</td>\n",
       "      <td>kyocera document solutions india private limit...</td>\n",
       "      <td>/home/parthpatil/Documents/testing_data/Data_3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>pnl_first_page</td>\n",
       "      <td>kyocera document solutions india private limit...</td>\n",
       "      <td>/home/parthpatil/Documents/testing_data/Data_3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>cc_first_page</td>\n",
       "      <td>weekly holiday on sunday ht hdfc bank  vatika ...</td>\n",
       "      <td>/home/parthpatil/Documents/testing_data/Data_3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>904 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       document_type                                               text  \\\n",
       "0      po_first_page  vendor code10221985 rotex manufacturers  engin...   \n",
       "1       po_next_page  10221985 otnheft rotex manufacturers  engineer...   \n",
       "2      po_first_page  vendor code10221985 rotex manufacturers  engin...   \n",
       "3       po_next_page  10221985 rotex manufacturers  engineers privat...   \n",
       "4      po_first_page  vendor code10221985 rotex manufacturers  engin...   \n",
       "..               ...                                                ...   \n",
       "899  gstn_first_page  amended government of india form gst reg06 see...   \n",
       "900   pnl_first_page  kyocera document solutions india private limit...   \n",
       "901   pnl_first_page  kyocera document solutions india private limit...   \n",
       "902   pnl_first_page  kyocera document solutions india private limit...   \n",
       "903    cc_first_page  weekly holiday on sunday ht hdfc bank  vatika ...   \n",
       "\n",
       "                                             file_name  \n",
       "0    /home/parthpatil/Documents/testing_data/Data_2...  \n",
       "1    /home/parthpatil/Documents/testing_data/Data_2...  \n",
       "2    /home/parthpatil/Documents/testing_data/Data_2...  \n",
       "3    /home/parthpatil/Documents/testing_data/Data_2...  \n",
       "4    /home/parthpatil/Documents/testing_data/Data_2...  \n",
       "..                                                 ...  \n",
       "899  /home/parthpatil/Documents/testing_data/Data_3...  \n",
       "900  /home/parthpatil/Documents/testing_data/Data_3...  \n",
       "901  /home/parthpatil/Documents/testing_data/Data_3...  \n",
       "902  /home/parthpatil/Documents/testing_data/Data_3...  \n",
       "903  /home/parthpatil/Documents/testing_data/Data_3...  \n",
       "\n",
       "[904 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('/home/hduser/Downloads/testing_dataset(1).csv')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b8ed8d9-de8e-4b73-a647-42556d6e3145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['document_type', 'text', 'file_name'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c88effef-2882-493c-bf5a-53a14f87e0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c68bc461-1003-4b00-99b8-8c06082d1bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f38f7a31-a822-4d13-addb-fe7d8de87135",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = label_encoder.fit_transform(df['document_type'].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77f9579c-6d92-4eb4-ad2f-3b8665459d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0723eef5-72b0-423a-9529-41ec14e8dc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "919166cc-aa23-4d56-b48e-06832f443140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_type</th>\n",
       "      <th>text</th>\n",
       "      <th>file_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>bs_first_page</td>\n",
       "      <td>vaulter engineering services private limited j...</td>\n",
       "      <td>/home/parthpatil/Documents/testing_data/Data_1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>bs_first_page</td>\n",
       "      <td>vaulter engineering services private limited j...</td>\n",
       "      <td>/home/parthpatil/Documents/testing_data/Data_1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>po_next_page</td>\n",
       "      <td>serpst 9182080 dt ganelivng neywey stivlac gn ...</td>\n",
       "      <td>/home/parthpatil/Documents/testing_data/Data_2...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>pnl_first_page</td>\n",
       "      <td>microfinish valves private limited standalone ...</td>\n",
       "      <td>/home/parthpatil/Documents/testing_data/Data_4...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>po_next_page</td>\n",
       "      <td>106274812 qtnref6500rfq0 purchase order cont a...</td>\n",
       "      <td>/home/parthpatil/Documents/testing_data/Data_4...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>pnl_first_page</td>\n",
       "      <td>ssh ee  a 6sz9s661ls llls7909 vl9t80vt 0 sot66...</td>\n",
       "      <td>/home/parthpatil/Documents/testing_data/Data_4...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>po_first_page</td>\n",
       "      <td>es reagent cane one  0 srr ett f204 meimucrire...</td>\n",
       "      <td>/home/parthpatil/Documents/testing_data/Data_4...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>po_next_page</td>\n",
       "      <td>10206542 qtnrefdel201617 purchase order cont  ...</td>\n",
       "      <td>/home/parthpatil/Documents/testing_data/Data_4...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>po_next_page</td>\n",
       "      <td>anicrofivish valves private lianited aa  works...</td>\n",
       "      <td>/home/parthpatil/Documents/testing_data/Data_2...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>po_next_page</td>\n",
       "      <td>17 of 230</td>\n",
       "      <td>/home/parthpatil/Documents/testing_data/Data_2...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>723 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      document_type                                               text  \\\n",
       "219   bs_first_page  vaulter engineering services private limited j...   \n",
       "221   bs_first_page  vaulter engineering services private limited j...   \n",
       "92     po_next_page  serpst 9182080 dt ganelivng neywey stivlac gn ...   \n",
       "291  pnl_first_page  microfinish valves private limited standalone ...   \n",
       "527    po_next_page  106274812 qtnref6500rfq0 purchase order cont a...   \n",
       "..              ...                                                ...   \n",
       "732  pnl_first_page  ssh ee  a 6sz9s661ls llls7909 vl9t80vt 0 sot66...   \n",
       "298   po_first_page  es reagent cane one  0 srr ett f204 meimucrire...   \n",
       "617    po_next_page  10206542 qtnrefdel201617 purchase order cont  ...   \n",
       "18     po_next_page  anicrofivish valves private lianited aa  works...   \n",
       "129    po_next_page                                          17 of 230   \n",
       "\n",
       "                                             file_name  label  \n",
       "219  /home/parthpatil/Documents/testing_data/Data_1...      0  \n",
       "221  /home/parthpatil/Documents/testing_data/Data_1...      0  \n",
       "92   /home/parthpatil/Documents/testing_data/Data_2...     10  \n",
       "291  /home/parthpatil/Documents/testing_data/Data_4...      7  \n",
       "527  /home/parthpatil/Documents/testing_data/Data_4...     10  \n",
       "..                                                 ...    ...  \n",
       "732  /home/parthpatil/Documents/testing_data/Data_4...      7  \n",
       "298  /home/parthpatil/Documents/testing_data/Data_4...      9  \n",
       "617  /home/parthpatil/Documents/testing_data/Data_4...     10  \n",
       "18   /home/parthpatil/Documents/testing_data/Data_2...     10  \n",
       "129  /home/parthpatil/Documents/testing_data/Data_2...     10  \n",
       "\n",
       "[723 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a6ab5b-297b-4b5a-a399-b3d95eeeb144",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96cc0ded-4d2e-4702-8290-6266f5fadfdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_type</th>\n",
       "      <th>text</th>\n",
       "      <th>file_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>bs_next_page</td>\n",
       "      <td>ls9egsttz telo6l9 z898svt0z tittlever 0 st8tes...</td>\n",
       "      <td>/home/parthpatil/Documents/testing_data/Data_4...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>po_next_page</td>\n",
       "      <td>ye 8ere60 slotoie ot lb 1 of 1809 clixo cn te ...</td>\n",
       "      <td>/home/parthpatil/Documents/testing_data/Data_2...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>po_next_page</td>\n",
       "      <td>10253714 qtnrefteni00006 purchase ordercont br...</td>\n",
       "      <td>/home/parthpatil/Documents/testing_data/Data_4...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>udyam_first_page</td>\n",
       "      <td>12302020 print  udyam registration certificate...</td>\n",
       "      <td>/home/parthpatil/Documents/testing_data/Data_3...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>gstn_first_page</td>\n",
       "      <td>amended government of india form gst reg06 see...</td>\n",
       "      <td>/home/parthpatil/Documents/testing_data/Data_2...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>po_next_page</td>\n",
       "      <td>10274070 purchase order cont  qtnref severn gl...</td>\n",
       "      <td>/home/parthpatil/Documents/testing_data/Data_4...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>pnl_first_page</td>\n",
       "      <td>part ll  form of statement of profit and loss ...</td>\n",
       "      <td>/home/parthpatil/Documents/testing_data/Data_1...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>po_next_page</td>\n",
       "      <td>19 of 230</td>\n",
       "      <td>/home/parthpatil/Documents/testing_data/Data_2...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>bs_first_page</td>\n",
       "      <td>particulars equity and liabilities shareholder...</td>\n",
       "      <td>/home/parthpatil/Documents/testing_data/Data_2...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>pnl_first_page</td>\n",
       "      <td>buola enginfers private limited for the ye ed ...</td>\n",
       "      <td>/home/parthpatil/Documents/testing_data/Data_4...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        document_type                                               text  \\\n",
       "749      bs_next_page  ls9egsttz telo6l9 z898svt0z tittlever 0 st8tes...   \n",
       "56       po_next_page  ye 8ere60 slotoie ot lb 1 of 1809 clixo cn te ...   \n",
       "492      po_next_page  10253714 qtnrefteni00006 purchase ordercont br...   \n",
       "897  udyam_first_page  12302020 print  udyam registration certificate...   \n",
       "93    gstn_first_page  amended government of india form gst reg06 see...   \n",
       "..                ...                                                ...   \n",
       "835      po_next_page  10274070 purchase order cont  qtnref severn gl...   \n",
       "241    pnl_first_page  part ll  form of statement of profit and loss ...   \n",
       "131      po_next_page                                          19 of 230   \n",
       "139     bs_first_page  particulars equity and liabilities shareholder...   \n",
       "317    pnl_first_page  buola enginfers private limited for the ye ed ...   \n",
       "\n",
       "                                             file_name  label  \n",
       "749  /home/parthpatil/Documents/testing_data/Data_4...      1  \n",
       "56   /home/parthpatil/Documents/testing_data/Data_2...     10  \n",
       "492  /home/parthpatil/Documents/testing_data/Data_4...     10  \n",
       "897  /home/parthpatil/Documents/testing_data/Data_3...     13  \n",
       "93   /home/parthpatil/Documents/testing_data/Data_2...      4  \n",
       "..                                                 ...    ...  \n",
       "835  /home/parthpatil/Documents/testing_data/Data_4...     10  \n",
       "241  /home/parthpatil/Documents/testing_data/Data_1...      7  \n",
       "131  /home/parthpatil/Documents/testing_data/Data_2...     10  \n",
       "139  /home/parthpatil/Documents/testing_data/Data_2...      0  \n",
       "317  /home/parthpatil/Documents/testing_data/Data_4...      7  \n",
       "\n",
       "[181 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fba1ab0c-abfe-47ed-8a49-b22ede93f19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hduser/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f333eab2a114ba0bf1255170caff708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/723 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ce40fcfbd1347f6bbd2e3d3260d27f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/181 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import transformers\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# Convert datasets to tokenized format\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "def tokenize_data(examples):\n",
    "    texts = examples[\"text\"]\n",
    "\n",
    "    # Ensure that texts are in list format\n",
    "    if isinstance(texts, str):  # Single string, convert to a list\n",
    "        texts = [texts]\n",
    "    elif isinstance(texts, list):  # If it's a list, check that all elements are strings\n",
    "        texts = [str(text) for text in texts]\n",
    "    else:\n",
    "        raise TypeError(f\"Expected list or str for 'text', got {type(texts)}\")\n",
    "\n",
    "    return tokenizer(texts, truncation=True, padding=True)\n",
    "\n",
    "tokenized_train = train_dataset.map(tokenize_data, batched=True)\n",
    "tokenized_test = test_dataset.map(tokenize_data, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2fd7fd4a-a631-469d-8ff1-655d3b8fc890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['document_type', 'text', 'file_name', 'label', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 181\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1a275b4-ce53-441e-b590-aa3243dfdee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1+cu121\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5c6ae1e-343c-4758-b982-afa8ece007d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tf-keras in /home/hduser/.local/lib/python3.10/site-packages (2.17.0)\n",
      "Requirement already satisfied: tensorflow<2.18,>=2.17 in /home/hduser/.local/lib/python3.10/site-packages (from tf-keras) (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/hduser/.local/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/hduser/.local/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /home/hduser/.local/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/hduser/.local/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/hduser/.local/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /home/hduser/.local/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/hduser/.local/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /home/hduser/.local/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/hduser/.local/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (3.3.0)\n",
      "Requirement already satisfied: packaging in /home/hduser/.local/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/hduser/.local/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/hduser/.local/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /home/hduser/.local/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (69.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/hduser/.local/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/hduser/.local/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/hduser/.local/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/hduser/.local/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (1.66.1)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in /home/hduser/.local/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (2.17.1)\n",
      "Requirement already satisfied: keras>=3.2.0 in /home/hduser/.local/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (3.5.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/hduser/.local/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (0.37.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /home/hduser/.local/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow<2.18,>=2.17->tf-keras) (0.37.1)\n",
      "Requirement already satisfied: rich in /home/hduser/.local/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras) (13.7.1)\n",
      "Requirement already satisfied: namex in /home/hduser/.local/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras) (0.0.8)\n",
      "Requirement already satisfied: optree in /home/hduser/.local/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/hduser/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf-keras) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf-keras) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf-keras) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/hduser/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf-keras) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/hduser/.local/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf-keras) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/hduser/.local/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/hduser/.local/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf-keras) (2.3.8)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/hduser/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf-keras) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/hduser/.local/lib/python3.10/site-packages (from rich->keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/hduser/.local/lib/python3.10/site-packages (from rich->keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/hduser/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97a8a9c4-c6a9-4515-bebe-c61eebf28f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers[torch] in /home/hduser/.local/lib/python3.10/site-packages (4.45.1)\n",
      "Requirement already satisfied: filelock in /home/hduser/.local/lib/python3.10/site-packages (from transformers[torch]) (3.13.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/hduser/.local/lib/python3.10/site-packages (from transformers[torch]) (0.25.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/hduser/.local/lib/python3.10/site-packages (from transformers[torch]) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/hduser/.local/lib/python3.10/site-packages (from transformers[torch]) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/hduser/.local/lib/python3.10/site-packages (from transformers[torch]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/hduser/.local/lib/python3.10/site-packages (from transformers[torch]) (2024.7.24)\n",
      "Requirement already satisfied: requests in /home/hduser/.local/lib/python3.10/site-packages (from transformers[torch]) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/hduser/.local/lib/python3.10/site-packages (from transformers[torch]) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/hduser/.local/lib/python3.10/site-packages (from transformers[torch]) (0.20.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/hduser/.local/lib/python3.10/site-packages (from transformers[torch]) (4.66.5)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in /home/hduser/.local/lib/python3.10/site-packages (from transformers[torch]) (0.34.2)\n",
      "Requirement already satisfied: torch in /home/hduser/.local/lib/python3.10/site-packages (from transformers[torch]) (2.4.1)\n",
      "Requirement already satisfied: psutil in /home/hduser/.local/lib/python3.10/site-packages (from accelerate>=0.26.0->transformers[torch]) (6.0.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/hduser/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers[torch]) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/hduser/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers[torch]) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/hduser/.local/lib/python3.10/site-packages (from torch->transformers[torch]) (1.13.1)\n",
      "Requirement already satisfied: networkx in /home/hduser/.local/lib/python3.10/site-packages (from torch->transformers[torch]) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/hduser/.local/lib/python3.10/site-packages (from torch->transformers[torch]) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/hduser/.local/lib/python3.10/site-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/hduser/.local/lib/python3.10/site-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/hduser/.local/lib/python3.10/site-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/hduser/.local/lib/python3.10/site-packages (from torch->transformers[torch]) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/hduser/.local/lib/python3.10/site-packages (from torch->transformers[torch]) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/hduser/.local/lib/python3.10/site-packages (from torch->transformers[torch]) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/hduser/.local/lib/python3.10/site-packages (from torch->transformers[torch]) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/hduser/.local/lib/python3.10/site-packages (from torch->transformers[torch]) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/hduser/.local/lib/python3.10/site-packages (from torch->transformers[torch]) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/hduser/.local/lib/python3.10/site-packages (from torch->transformers[torch]) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/hduser/.local/lib/python3.10/site-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/hduser/.local/lib/python3.10/site-packages (from torch->transformers[torch]) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/hduser/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.6.77)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/hduser/.local/lib/python3.10/site-packages (from requests->transformers[torch]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers[torch]) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->transformers[torch]) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/hduser/.local/lib/python3.10/site-packages (from requests->transformers[torch]) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/hduser/.local/lib/python3.10/site-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/hduser/.local/lib/python3.10/site-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3940d7b1-1bd0-4913-a887-94e7d800d928",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as YashSuryawanshi2023\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as YashSuryawanshi2023\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 17:59, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.476700</td>\n",
       "      <td>0.952027</td>\n",
       "      <td>0.740331</td>\n",
       "      <td>0.371436</td>\n",
       "      <td>0.362148</td>\n",
       "      <td>0.326070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 04:26]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "import numpy as np\n",
    "# Load pre-trained DistilBERT model for sequence classification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=15)\n",
    "\n",
    "# Prepare data collator for padding sequences\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Define compute_metrics function\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = np.argmax(pred.predictions, axis=1)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    acc = accuracy_score(labels, preds)\n",
    "\n",
    "    # Calculate precision (macro)\n",
    "    precision = precision_score(labels, preds, average=\"macro\")\n",
    "\n",
    "    # Calculate recall (macro)\n",
    "    recall = recall_score(labels, preds, average=\"macro\")\n",
    "\n",
    "    # Calculate F1 score (macro)\n",
    "    f1 = f1_score(labels, preds, average=\"macro\")\n",
    "\n",
    "    # Generate classification report\n",
    "    report = classification_report(labels, preds, output_dict=True)\n",
    "\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "    }\n",
    "\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/home/hduser/Documents/results\",\n",
    "    learning_rate=2e-4,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\"\n",
    ")\n",
    "\n",
    "# Define Trainer object for training the model\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics  # Include metrics in the training process\n",
    "\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Save the trained model\n",
    "trainer.save_model('model')\n",
    "\n",
    "# Evaluate on both training and test datasets\n",
    "train_metrics = trainer.evaluate(eval_dataset=tokenized_train)\n",
    "test_metrics = trainer.evaluate(eval_dataset=tokenized_test)\n",
    "\n",
    "# Print training and testing accuracy and F1 scores\n",
    "print(\"Training Metrics:\", train_metrics)\n",
    "print(\"Testing Metrics:\", test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf668d1d-ad93-4ecf-b6db-732a2020b926",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /home/hduser/.local/lib/python3.10/site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /home/hduser/.local/lib/python3.10/site-packages (from seaborn) (2.0.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /home/hduser/.local/lib/python3.10/site-packages (from seaborn) (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/hduser/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/hduser/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/hduser/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/hduser/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/hduser/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/hduser/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/hduser/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/hduser/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas>=1.2->seaborn) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/hduser/.local/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5676ef59-159f-4ae0-b2ec-f8e530ff6ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm,class_names, title):\n",
    "    # plt.figure(figsize=(10, 8))\n",
    "    # sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    # plt.title(title)\n",
    "    # plt.ylabel('True label')\n",
    "    # plt.xlabel('Predicted label')\n",
    "    # plt.show()\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Function to print detailed results\n",
    "def print_detailed_results(dataset_name, metrics, labels, predictions,all_class_names):\n",
    "    print(f\"\\n{'='*20} {dataset_name} Results {'='*20}\")\n",
    "\n",
    "    print(\"\\n1. Overall Metrics:\")\n",
    "    print(f\"   Accuracy:  {metrics['eval_accuracy']:.4f}\")\n",
    "    print(f\"   Precision: {metrics['eval_precision']:.4f}\")\n",
    "    print(f\"   Recall:    {metrics['eval_recall']:.4f}\")\n",
    "    print(f\"   F1 Score:  {metrics['eval_f1']:.4f}\")\n",
    "\n",
    "    unique_classes = sorted(set(labels) | set(predictions))\n",
    "    class_names = [all_class_names[i] for i in unique_classes]\n",
    "\n",
    "    print(\"\\n2. Confusion Matrix:\")\n",
    "    cm = confusion_matrix(labels, predictions)\n",
    "    print(cm)\n",
    "    plot_confusion_matrix(cm,class_names, f\"{dataset_name} Confusion Matrix\")\n",
    "\n",
    "    print(\"\\n3. Detailed Classification Report:\")\n",
    "    report = classification_report(labels, predictions,target_names=class_names, output_dict=True)\n",
    "\n",
    "    # # Print per-class metrics\n",
    "    # print(\"\\n   Per-class Metrics:\")\n",
    "    # print(\"   {:<10} {:<12} {:<12} {:<12} {:<12}\".format(\"Class\", \"Precision\", \"Recall\", \"F1-score\", \"Support\"))\n",
    "    # print(\"   \" + \"-\"*58)\n",
    "    # for class_name, class_metrics in report.items():\n",
    "    #     if isinstance(class_metrics, dict):\n",
    "    #         print(\"   {:<10} {:<12.4f} {:<12.4f} {:<12.4f} {:<12}\".format(\n",
    "    #             class_name,\n",
    "    #             class_metrics['precision'],\n",
    "    #             class_metrics['recall'],\n",
    "    #             class_metrics['f1-score'],\n",
    "    #             class_metrics['support']\n",
    "    #         ))\n",
    "\n",
    "    # # Print average metrics\n",
    "    # print(\"\\n   Average Metrics:\")\n",
    "    # print(\"   {:<10} {:<12.4f} {:<12.4f} {:<12.4f}\".format(\n",
    "    #     \"Macro Avg\",\n",
    "    #     report['macro avg']['precision'],\n",
    "    #     report['macro avg']['recall'],\n",
    "    #     report['macro avg']['f1-score']\n",
    "    # ))\n",
    "    # print(\"   {:<10} {:<12.4f} {:<12.4f} {:<12.4f}\".format(\n",
    "    #     \"Weighted Avg\",\n",
    "    #     report['weighted avg']['precision'],\n",
    "    #     report['weighted avg']['recall'],\n",
    "    #     report['weighted avg']['f1-score']\n",
    "    # ))\n",
    "    print(\"reports:\",report)\n",
    "    return report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "405bb45f-eb23-412d-b5a8-43a7127d59b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = label_encoder.classes_\n",
    "len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95e04cd7-4229-4661-9044-af4d2525ab48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hduser/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m test_labels, test_predictions \u001b[38;5;241m=\u001b[39m test_output\u001b[38;5;241m.\u001b[39mlabel_ids, np\u001b[38;5;241m.\u001b[39margmax(test_output\u001b[38;5;241m.\u001b[39mpredictions, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Print detailed results for both datasets\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# print_detailed_results(\"Training\", train_metrics, train_labels, train_predictions,class_names)\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m class_report_dict\u001b[38;5;241m=\u001b[39mprint_detailed_results(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mtest_metrics\u001b[49m, test_labels, test_predictions,class_names)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_metrics' is not defined"
     ]
    }
   ],
   "source": [
    "# Get predictions for training and test sets\n",
    "train_output = trainer.predict(tokenized_train)\n",
    "test_output = trainer.predict(tokenized_test)\n",
    "\n",
    "train_labels, train_predictions = train_output.label_ids, np.argmax(train_output.predictions, axis=1)\n",
    "test_labels, test_predictions = test_output.label_ids, np.argmax(test_output.predictions, axis=1)\n",
    "\n",
    "# Print detailed results for both datasets\n",
    "# print_detailed_results(\"Training\", train_metrics, train_labels, train_predictions,class_names)\n",
    "class_report_dict=print_detailed_results(\"Testing\", test_metrics, test_labels, test_predictions,class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3dcbb7c5-f6b0-464d-b927-470b55f8acac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bs_first_page': {'precision': 0.2682926829268293,\n",
       "  'recall': 1.0,\n",
       "  'f1-score': 0.4230769230769231,\n",
       "  'support': 11.0},\n",
       " 'bs_next_page': {'precision': 0.2972972972972973,\n",
       "  'recall': 0.6470588235294118,\n",
       "  'f1-score': 0.4074074074074074,\n",
       "  'support': 17.0},\n",
       " 'cc_first_page': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 3.0},\n",
       " 'cin_first_page': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 2.0},\n",
       " 'gstn_first_page': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 7.0},\n",
       " 'gstn_next_page': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 7.0},\n",
       " 'itr_first_page': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 5.0},\n",
       " 'pnl_first_page': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 23.0},\n",
       " 'pnl_next_page': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 2.0},\n",
       " 'po_first_page': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 7.0},\n",
       " 'po_next_page': {'precision': 0.8737864077669902,\n",
       "  'recall': 1.0,\n",
       "  'f1-score': 0.9326424870466321,\n",
       "  'support': 90.0},\n",
       " 'poa_next_page': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 1.0},\n",
       " 'udyam_first_page': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 3.0},\n",
       " 'udyam_next_page': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 3.0},\n",
       " 'accuracy': 0.6187845303867403,\n",
       " 'macro avg': {'precision': 0.10281259914222263,\n",
       "  'recall': 0.18907563025210083,\n",
       "  'f1-score': 0.12593762982364018,\n",
       "  'support': 181.0},\n",
       " 'weighted avg': {'precision': 0.4787074600291618,\n",
       "  'recall': 0.6187845303867403,\n",
       "  'f1-score': 0.5277215243865689,\n",
       "  'support': 181.0}}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_report_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b3de71aa-309c-47fa-8f46-cf10195abb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "464bdbf4-378b-4cfd-92b3-f6b347e75da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"Document Classification Using DistilBert For New Data-1\")\n",
    "\n",
    "with mlflow.start_run(nested=True):\n",
    "    mlflow.log_params({\n",
    "        \"model_name\": \"distilbert-base-uncased\",\n",
    "        \"num_labels\": 15,\n",
    "        \"learning_rate\": training_args.learning_rate,\n",
    "        \"batch_size\": training_args.per_device_train_batch_size,\n",
    "        \"num_epochs\": training_args.num_train_epochs,\n",
    "        \"weight_decay\": training_args.weight_decay,\n",
    "    })\n",
    "    mlflow.log_metrics({\n",
    "        \"train_accuracy\": train_metrics['eval_accuracy'],\n",
    "        \"train_f1\": train_metrics['eval_f1'],\n",
    "        \"test_accuracy\": test_metrics['eval_accuracy'],\n",
    "        \"test_f1\": test_metrics['eval_f1'],\n",
    "    })\n",
    "\n",
    "    for class_name, metrics in class_report_dict.items():\n",
    "        # Check if the item is a class (not 'accuracy', 'macro avg', or 'weighted avg')\n",
    "        if isinstance(metrics, dict) and 'precision' in metrics:\n",
    "            mlflow.log_metric(f'{class_name}_precision', metrics['precision'])\n",
    "            mlflow.log_metric(f'{class_name}_recall', metrics['recall'])\n",
    "            mlflow.log_metric(f'{class_name}_f1_score', metrics['f1-score'])\n",
    "            mlflow.log_metric(f'{class_name}_support', metrics['support'])\n",
    "        \n",
    "        # Log overall accuracy if it's available\n",
    "        if 'accuracy' in class_report_dict:\n",
    "            mlflow.log_metric('accuracy', class_report_dict['accuracy'])\n",
    "        \n",
    "        # Log macro and weighted averages if available\n",
    "        for avg_type in ['macro avg', 'weighted avg']:\n",
    "            if avg_type in class_report_dict:\n",
    "                for metric, value in class_report_dict[avg_type].items():\n",
    "                    mlflow.log_metric(f'{avg_type}_{metric}', value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7bd971-c2be-4d5b-90b1-1a809d659a15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e80c977-2e52-49a3-bebd-c8338f78a54c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=15, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Load the saved model and tokenizer\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"model\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"model\")\n",
    "\n",
    "# Set model to evaluation model\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9780e317-2e70-4963-9403-64f0be3e658c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pdfminer.high_level import extract_text\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "\n",
    "def extract_text_from_page(pdf_file_path, page_number):\n",
    "    with open(pdf_file_path, 'rb') as file:\n",
    "        text = extract_text(file, page_numbers=[page_number])\n",
    "    return text\n",
    "\n",
    "# Function to extract text from an image using pytesseract\n",
    "def extract_text_from_image(image):\n",
    "    text = pytesseract.image_to_string(image,lang='eng')\n",
    "    return text\n",
    "\n",
    "# Function to clean up and concatenate the extracted text\n",
    "def clean_and_concatenate_text(text):\n",
    "    # Split text into lines, strip extra spaces, and join lines with a single space\n",
    "    lines = text.splitlines()\n",
    "    cleaned_lines = [re.sub(r'\\s+', ' ', line).strip() for line in lines if line.strip()]\n",
    "    concatenated_text = ' '.join(cleaned_lines)\n",
    "    concatenated_text = re.sub(r'_+|[^a-zA-Z0-9\\s]', '', concatenated_text)\n",
    "\n",
    "    return concatenated_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97f85e7e-8407-43c6-bd46-3b2a6e5fe56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 0 is an image. Extracting text using OCR...\n",
      "Page text extracted using OCR en by these presents that we vaulter engineering rivate limited having its office at 62a lajpat nagar jagatpura jaipur  r nagendra singh aged about 36 years residing at jaipur do hercby nominate appoint one of our directors ic mr nagendra singil son of sh gajraj singh about 38 years as our as our true and jawlul attorney and o do execute and perform ss  alors the following acts deeds and things for and on behalf of the company with respect  b lenders and bidding processes applicdinitiatedperformed by the company hhorities or public sector undertakings district boards or municipal boards andor any ter localjurisdictional concerned authority f 2 togsubmit proposal participate and negotiate in respect of the any bidtender in the name ds plead sign and verify tendercontract of agreement and any other tender related si tofirgue negotiate and lo accept awards issued by tendering authorities in the name ol 3 nn  wy  5 oy sy og   to grepare file and submit any application complaint letter communication as may be re  a i i tenders and bidding  pracesses os ze 4 db hen and execule necessary forms documents and papers as may be necessary to be i ad subibitted with the concerned department authority for various tenders and bidding 1  x v procgsses applicdinitiatedperformed by the company i al  od i  arpesso i   e 7  page fof 2 bir yeu fat vault enieeng senigy lt  not yehoie y wan we il ra  yn iy ps nq zs dit ector\n",
      "Predicted labels: [11]\n",
      "Predicted document types: ['poa_first_page']\n",
      "Page 1 is an image. Extracting text using OCR...\n",
      "Page text extracted using OCR matters in this context and to repres  pany before the relevant department authority for various tenders and bidding processes appliedinitiatedperformed by the company 10 to perform the work as awarded and to execute the same according to the tender in the name of the company 11 to do all lawful acts deeds and things and to execute all such documents as may be necessary with respect to the above and we vaulter engineering services private limited hereby confirm that all acts deeds and things lawfully done or caused to be done by our said attorney shall be construed as acts deeds and things done by the company and we undertake to ratify all and whatsoever the said attorney shal lawfully do or cause to be done on my behalf by virtue of these presents in witness whereof 1 mrs surabhi singh director of the company have hereto signed at jaipur on this 15 day of october 2018 fol bts etd engr arins services private limited qur beh eng ca singh director directorexecutant accepted my 2 nagrndra slngh a attorney o dee hex we   6  a t  2  i wa  a jo a ao  5  ys pal  jaipup rs pie ordo wor a vnd 24 ly page 2 af2\n",
      "Predicted labels: [11]\n",
      "Predicted document types: ['poa_first_page']\n"
     ]
    }
   ],
   "source": [
    "pdf_file_path = \"/home/parthpatil/Documents/testing_data/Data_1/VAULTER ENGINEERING SERVICES P LTD/poa/POA.pdf\"\n",
    "\n",
    "\n",
    "with open(pdf_file_path, 'rb') as file:\n",
    "    pages = list(PDFPage.get_pages(file))\n",
    "\n",
    "for i, _ in enumerate(pages):\n",
    "  pdf_text = extract_text_from_page(pdf_file_path, i)\n",
    "  cleaned_pdf_text = clean_and_concatenate_text(pdf_text)\n",
    "\n",
    "  if cleaned_pdf_text:\n",
    "      text = cleaned_pdf_text\n",
    "      print(\"Page text extracted using pdfminer\",text)\n",
    "  else:\n",
    "      print(f\"Page {i} is an image. Extracting text using OCR...\")\n",
    "      images = convert_from_path(pdf_file_path, first_page=i+1, last_page=i+1)\n",
    "      image = images[0]\n",
    "      ocr_text = extract_text_from_image(image)\n",
    "      text = clean_and_concatenate_text(ocr_text)\n",
    "      print(\"Page text extracted using OCR\",text)\n",
    "\n",
    "# Tokenize the input texts\n",
    "  inputs = tokenizer(text, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "\n",
    "  # Perform inference (make predictions)\n",
    "  with torch.no_grad():\n",
    "      outputs = model(**inputs)\n",
    "\n",
    "  # Get the logits (raw scores)\n",
    "  logits = outputs.logits\n",
    "\n",
    "  # Convert logits to predicted labels (get the index of the highest value)\n",
    "  predictions = torch.argmax(logits, dim=-1).numpy()\n",
    "\n",
    "  # Print the predicted labels\n",
    "  print(\"Predicted labels:\", predictions)\n",
    "\n",
    "  # (Optional) Map labels back to original class names if LabelEncoder was used\n",
    "  predicted_labels = label_encoder.inverse_transform(predictions)\n",
    "  print(\"Predicted document types:\", predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6ec6ba-d86c-4bea-a8f8-7e2409ccd255",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
